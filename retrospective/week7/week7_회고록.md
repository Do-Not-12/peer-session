## [ 렉사(조예진) 회고 ]

베이스 코드
- 대회형 프로젝트 참가는 처음이여서 나만의 베이스코드를 만들려는 시도를 며칠간 하다가, 도저히 속도가 안나서 조교님이 주신 템플릿으로 나머지 대회를 진행했다. 밑바닥부터 베이스 코드를 짜기에는 시간이 너무 부족했던 것 같다. 하지만 템플릿 코드를 사용하니 코드를 돌리면서도 어떤 설정으로 돌아가고 있는지 파악하지 못하고 러닝을 돌리는 상황이 되었다. 대회가 끝났으니 나만의 베이스 코드를 구성해보고 싶다.

환경 설정
- 항상 효율적인 실험 환경 설정이 중요하다고 생각해왔다. 이번에도 도커를 이용해서 팀원들과 같은 환경을 구축하기 위해 도커를 설치하려고 했는데, 제공된 서버가 도커 컨테이너이고 도커 in 도커는 불가능하다는것을 너무 늦게 알아버렸다.
- shell 파일을 이용해서 실행하면 터미널에서 실수하지 않고 깔끔하게 실행할 수 있다는 사실을 알고, 적용했다.

시도 
모델 바꾸기
- 모델을 변경하는데 큰 기대를 걸어서, 여러가지 모델을 사용해 보았다. Resnet18, resnet50, wideresnet-28-10, 그리고 object detection의 계보라던 Darknet53까지 써보았지만 큰 차이는 없었다.

손수 하는 EDA
- 대회 이틀 전부터, 우리 팀의 모델이 왜이렇게 성능을 못내는지를 이해하기가 힘들었다. 그래서 데이터를 하나하나 까서 보기로 생각했다. Train 데이터셋을 살펴봤고, Test 데이터셋도 보았는데 이상하게 Test 데이터셋에 청년(0~30세), 노인(60세~)의 분포가 Train보다 많은 것 같았다. 

- 그리고 팀 내 최고 성능을 내는 폴라의 csv파일을 열어서 Test 데이터셋과 하나씩 비교하면서 보았다. 나이를 제외한 성별과 마스크 착용 여부는 정확하게 맞추고 있었다. 그래서 나이만 판단하는 모델을 Resnet18로 만들어서 돌려보았는데, Train set의 분포와 거의 같은 비율로 예측 하는 결과가 나왔다. Test 데이터셋의 분포로 결과가 나오는 것이 아니라, Train 데이터셋의 경향성을 반영한 결과가 생성되고 있었던 것이다.
 
- 따라서 노인 연령대에 대한 Data Augmentation을 해서 노인 데이터의 비율을 높여야 겠다는 생각이 들었다. 이날이 대회 마지막날 6시간 전이라서, 코드를 짜고 러닝을 돌릴 시간이 부족했다. 마침 피터가 이미 해본 시도여서, 피터가 준 csv파일을 열어서 나이의 분포를 관측했더니 내가 원하는 결과가 나오고 있었다. 

손수 하는 앙상블 기법
- 따라서 폴라의 csv파일의 성별, 마스크 착용 여부와 피터의 csv파일에서 나이 예측 결과만 간단한 파이썬 코드로 합쳐서 제출해보았더니 무려 47등에서 16등까지 오르는 기적이 발생했다.  

팀플레이
- 초기에 coding convention과 git 협업 룰을 정했지만 막상 활용은 잘 하지 못했다. 프로젝트에 여러 변동이 많고 시간적 한계가 있다 보니 한가지 규칙으로 이끌어 가는 것이 쉽지 않았다. 

## [ Doritos(진완혁) 회고 ]
- 먼저 간단하게 데이터의 분포를 확인했다.
성별 => 남성 : 1042, 여성 : 1658
마스크 착용 여부 => 착용 : 13500, 미착용 : 2700, 이상하게 착용 : 2700
나이 => 30 미만 : 1281, 30 이상 60 미만 : 1227, 60 이상 : 192

데이터 탐색을 통해 데이터 불균형이 상당하다는 것을 확인했다.
특히 60세 이상은 2700명 중 단 192명만 존재했기 때문에 데이터가 굉장히 부족했다.

- 대회형 프로젝트 참여는 처음이여서 모든 코드를 모듈화하여 훈련시키고 결과를 도출해내는 과정이 굉장히 낯설고 베이스라인 코드를 이해하는 데에 많은 어려움이 있었다.
베이스라인 코드를 이해를 하더라고 온전히 남이 짠 코드를 활용하기 보다는 내가 생각하고 구상한대로 모델을 구성해보고 싶었다.
 먼저 베이스라인 코드의 구조와 각 기능을 이해하기 위해 스페셜 미션부터 차근차근 공부했다. 데이터 불균형 문제를 어느 정도 완화시킬 수 있는 여러 방법이 있었다.
Augmentation, Loss Function, Labeling 등 대회를 진행할 데이터를 통해 여러 방법에 대해 친절히 설명을 해줘서 Train과 Inference를 하는 과정에서 왜 모듈화를 하는지 이해하는 데에 큰 도움이 됐다.

- 모델 구성 과정
Pretrained Model 활용.
→ 성능이 좋다고 알려진 기존의 모델을 베이스라인 코드에 적용해봤다.
→ 이미지 Resize, CenterCrop, Colorjitter 등 여러가지 transform을 거친 후 20%의 검증세트의 결과를 확인하면 생각보다 좋지 않았다.
→ resnet과 vgg19 모델을 사용했지만 resnet18은 성능, resnet34와 vgg19는 훈련 시간 문제로 최종 모델로 활용하지 못 했다.

Pretrained Model 알고리즘 직접 구현
→ Resize와 CenterCrop을 통해 이미지 크기가 줄어들었지만 224x224 크기의 데이터를 적용시키기에 용이한 ResNet모델의 7x7 커널을 사용하기에는 부적절하다는 생각이 들었다.
→ ResNet 알고리즘을 직접 구현을 하면 마음대로 커스텀하기도 수월하기 때문에 코드를 직접 짜고 커널 사이즈를 3x3으로 줄인 후 학습률을 대폭 낮춰 이미지의 세세한 정보를 뽑아내도록 유도했다.
→ 그러나 이미지 사이즈를 줄여서(압축시켜서) 정보를 뽑아내는 것에 대한 어려움과 60세 이상 데이터의 부족함으로 인해 큰 성능 향상을 보지 못 했다.

이미지 사이즈와 라벨링
→ 이미지 사이즈를 최대한 원본과 유사하게 하여 많은 정보를 담기 위해 Resize와 CenterCrop을 기존과 대비해 크게 변환하고 ResNet의 커널 사이즈를 크게하여 훈련 시간을 줄였다.
→ eval 데이터에는 60세 이상이 상당히 많이 분포하고 있는 것으로 판단하여 train 데이터의 58세 이상을 60세 이상으로 라벨링 후 훈련을 하여 최종적으로 가장 좋은 성능을 이끌어냈다.

- 이번 프로젝트에서 데이터의 중요성을 다시 한 번 더 깨닫게 됐다.
시간이 많이 부족해서 여러 가지 더 많은 시도를 해보지 못했는데 대표적으로 K-Fold와 60세 이상 데이터에만 Augmentation을 적용하여 훈련을 시키지 못 한 것이 아쉽다. 또한 나이, 성별, 마스크 모델을 각각 구성하여 결과를 내보고 싶은 욕심도 있었다. 여러가지 세세한 항목들을 바꿔가면서 약 60번의 모델을 학습시켰어도 부족하다는 느낌이 들었다.
 각자의 역량을 최대한으로 이끌어내어 모델 결과를 앙상블하여 높은 순위를 기록하면서 협업의 중요성과 필요성을 새삼 느꼈다.
다음 프로젝트에서도 꼭 협업의 장점을 활용하여 최고를 목표로 최선을 다 해봐야겠다!!


## [ Peter(박준형) 회고 ]

아쉬웠던 것

1. 실험 시각화 도구를 사용하지 않은것
Tensorboard와 Wand를 사용하지 않았다. 외부 서버에서 설치가 까다롭고 잘 되지 않았는데 다른 팀원 들이 중간의 실험 결과들을 모니터링 한 것이 도움이 많이 되었다고 해서 아쉬웠다.

2. 시간 계산을 못한것
마지막 까지 k-fold로 학습하던 모델이 대회 종료 시간 1시간 후에 마무리가 되어 사용하지못하였던게 매우 아쉬웠다. 추후에 멘토님에게 여쭤 보니 1 에폭으로 시간을 계산하는 방법, tqdm 모듈을 사용하는 방법, 중간에 학습이 끝나지 않더라도 결과를 저장하는 방법 등이 있다고 말씀해주셨다. 이 방법중 하나만 사용했더라도 마지막 결과가 더 올랐을거 같아서 아쉬웠다.

3. 기본에 충실하지 못한것
처음부터 Augmentation에 초점을 맞췄다. 하지만 GridShuffle, CannyEdges 같이 하드코어한 방법을 먼저 사용해서 결과가 좋지 않았다. 결국 마지막에 사용했던 horizonflip이나 GausianBlur 같은 방법들이 점수가 많이 올랐다. 오래 쓴 것은 그 나름대로의 이유가 있었을텐데 증명된 방법의 base에 여러 실험을 하는 것이 아닌 그 반대로 진행을 해서 좋은 결과가 나오지 못했던거 같다.

4. 생각만하고 시도하지못한 것
1,2등 팀 모두 swin transformer를 사용했었다. 난 심지어 피어세션 때 이 모델을 발표했고 처음에 사용을 고려했으나 잘 안되겠지? 최신 모델이라서 어렵겠지 라는 생각에 시도를 못해봤는데 이 모델을 시도해봤으면 좋은 결과가 나왔을거같은데 아쉬웠다.

5. 공유 문화를 활용 못한 것
팀원 중 폴라가 토론 게시판에 여러 글을 쓰고 자신의 결과를 공유하는 것을 보고 나도 다음 대회에는 꼭 하나라도 토론 게시판에 공유를 올려야 겠다고 생각들었다

잘했던 점

데이터 증강

60세 이상 데이터가 심하게 적었기 때문에 59세 라벨을 60세로 바꾸고, augmentation을 통해 데이터를 증강 했을 때 성능이 8~9% 이상이나 올랐다


성장한 점
BoostCamp에와서 실제로 내가 무언갓을 이루어 냈다는 것에 성취감을 얻었다
각자 모델을 학습했을 때는 사실 좋은 순위가 나오지 않았다. 거의 꼴등 근처의 순위었는데 팀과 협업을 하면서 의견을 조율하고, 서로의 모델을 앙상블 하면서 순위가 10위까지 올랐다. 진정한 협업의 의미를 깨닫게 되었다.
이론적으로만 배웠던 부분을 실제로 경험해보면서 현업 겪는 데이터 imbalanced 문제, overfitting문제 들에 대해 공감할 수 있었다.
간절하게 열심히 하면 뭐든 달성할 수 있다는 것을 느꼈다.


## [ Polar (박기범) 개인회고 ]

1. 프로젝트 기간 활동 요약
대회 데이터 EDA
베이스라인 코드 제공 이전에 나만의 템플릿으로 베이스라인 코드 완성해보기
기본적으로 pre-trained model을 다양하게 써보는 방식으로 접근했었음
	(ResNet, EfficientNet, RegNet 등등…)
클래스 불균형을 해결해보고자 data augmentation을 다양한 방법으로 시도했었음
단일 모델로는 한계가 있을 것으로 생각해서 클래스를 분리해서 클래스별로 모델을 학습해봄
K-Fold 방식을 활용해 앙상블 진행
wandb 연결 및 베이스라인 코드 분석을 통한 ML Engineering 코드 작성법 학습

2. 핵심 실험 과정과 실험을 통해 배운점
   1.  Data augmentation
       1.  CutMix
데이터 증강을 진행하지 않고 모델 학습을 진행한 결과 validation 과정에서 오분류 클래스 대부분이 연령의 경계구간 (30세 ± 2세, 60세 ± 2세)에 있었습니다. 이를 해결하고자 데이터 증강을 진행하였습니다. 데이터 증강과정에서 CutMix방식을 통해 원하는 클래스에 해당하는 데이터 2개를 샘플링하여 절반씩 합치는 방식을 채택했습니다. validation 자체에서는 성능지표가 높게 나와 실제 test에서 기대를 했으나 test score가 높게 나오지 않았습니다. 이후에 생각해보니 랜덤 샘플 2개를 선택해서 섞은 데이터를 쓰다보니 절반이 validation 과정에서 data leakage 현상으로 나타날 수 있다는 것을 알았습니다. 향후 이런 방법을 쓸 경우 주의해서 사용할 필요가 있을 것 같습니다.

       1. CenterCrop
주어진 이미지 데이터는 배경과 같은 불필요한 요소가 많았습니다. 이 요소들이 실제 이미지를 파악하고 분류할 때 방해를 줄 것이라 생각되어 해당 부분을 제거하는 방향으로 진행했습니다. 따라서 얼굴과 상반신 일부만 나오게 처리를 하였고 그 결과 마스크, 성별 분류에서는 뛰어난 성능 향상이 있었습니다. (F1 score 0.6869 -> 0.7000) 이 실험을 통해 데이터 자체에서 최대한 불필요한 부분을 제거할 필요가 있다는 생각이 들었습니다.

1. 아쉬웠던 점

MLOps 공부도 하고 다양한 데이터 분석관련 공부도 많이 했었는데 정작 데이터를 확인하지 않았다는 점에서 반성
좀 더 코드를 최적화한다던가 Airflow, PyTorch Lightning 등 다양한 하이퍼 파라미터 튜닝 및 코드 경량화 과정을 적용해보면서 engineering적 실력을 더 늘려보지 못한 것이 아쉽다

4. 배운점

많은 사람들이 실험을 할 때 편리하게 쓸 수 있는 코드 템플릿을 배울 수 있었음
모델과 데이터셋의 메모리적 활용에 대해 고민을 많이 해볼 수 있었음

## [ 써리 (이서희) 개인 회고 ]

1. Individual Objective: U stage기간동안 배웠던 이론과 기법들을 실제 이미지를 대상으로 실험함으로써, 모델링에 대한 구체적인 인사이트를 최대한 많이 얻는다.또한 해당 competition에서 실험해본 것들을 Notion과 GitHub에 기록함으로써 다음 P-stage와 추후 모델링 수행 시 밑거름으로 사용할 수 있도록 한다.
   
2. Trial 1 – Modeling
A. Overfitting
   - 배경: Train과 val의 성능차이가 심해 모델이 train data에서의 과적합을 해결하고자 했다
   - 실험 1: 배치정규화가 들어간 resnet모델의 경우 batch size가 과적합에 영향을 줄 수 있다고  하여 배치사이즈를 줄여봤으나 큰 차이는 없었다.
   - 실험 2: Loss를 f1 loss로 바꿨을 때 train f1 score가 조금 내려오는 경향을 보였다. 클래스의 불균형을 반영한 loss를 계산하며 수치가 조금 낮아진 것 같다.
   - 실험 3: 추후 image augmentation, ensemble기법을 사용해 validation score를 높임으로써 train set에 대한 과적합은 줄일 수 있었다.
  
B. Model type
   - 배경: 다양한 모델들을 적용해보지는 않았다. 모델보다는 들어가는 데이터에 대한 처리가 성능에 더 많은 영향을 미칠 것이라고 생각했기 때문이다. 그래서 프로젝트 후반에 다른 모델들을 적용해보는 방향을 택했다.
   - 실험 1: Resnet 18에서 resnet 34로 바꿨을 땐 성능 차이가 없었다. 결국 구조는 비슷하기 때문에 같은 데이터를 넣었을 때 비슷한 성능 차이가 나오는 것이라고 생각했다.
   - 실험 2: 그 후 k-fold training한 resnet18모델의 결과로 soft voting ensemble했더니 validation 기준 성능이 가장 높게 나왔다. 같은 모델이지만 다른 데이터로 학습시킨 결과를 집계한 것이기 때문에 높게 나왔다고 생각한다. Test 에 적용해보지는 못했다.

C. 그 외
Learning rate (scheduler), image classification, loss, gradient accumulation, optimizer 등의 요소들을 바꾸면서 실험을 진행했다. 차례로 실험을 수행하며 성능이 향상된 요소들을 적용한 모델에 추가로 다른 요소들을 적용하는 방식으로 진행했다.


3. Trial 2 – Image
A. 이미지 불균형
   - 배경: EDA를 통해 클래스간 불균형이 크고 실제로 분류도 잘 하지 못한다는 것을 확인했다.
   - 실험 1: 나이, 특히 60세와 그 근방 나이대의 클래스를 잘 분류하지 못하는 양상을 보였기에 이미지에서 눈으로 보기에 나이(주름,흰머리)가 잘 드러날 수 있는 transform 기법들을 적용해보았지만 오히려 성능이 안좋았다. 원본이미지에 대해 transform 시켰기 때문에 원본에서 추출할 수 있는 feature들을 손상시켜 이러한 결과가 나왔다고 생각한다.
   - 실험 2: 그 후 가장 데이터가 적은 60세 노인들에 대한 이미지 augmentation을 진행했다. 원본과 비슷하지 않도록 여러가지 transform기법(noise, colorjitter, flip, crop, brightcontrast)들을 적용하였다. 나이에서의 분포가 30대 미만과 비슷하도록 약 2600개의 이미지를 추가했다. 그 결과 validation기준으로 약 1%가 올랐다.
   
B. 그 외
   - Resize를 처음 진행했을 때엔 test set에서의 성능이 3%정도 올랐으나, 그 이후 여러 모델링기법과 augmentation등을 진행한 후에는 resize를 시킨 이미지들의 결과가 조금 더 좋지 않았다. Resize를 시킬 때 원본 이미지의 feature를 조금씩 손상시키기 때문에 그 손상 값들이 성능을 안 좋게 만들 수 있는 원인이 될 수 있겠다고 생각했다.
   - 처음엔 기존 이미지에 대한 처리를 먼저 진행해보았다. 배경에 모델이 덜 영향받도록 얼굴 부분만 crop으로 잘라보았다. Crop을 통해 얼굴만 나올 수 있도록 단순히 절대적인 위치 값으로 사진을 잘랐다. 그랬더니 성능이 조금 떨어졌다. 그런데 나중에 확인해보니, 얼굴이 잘 나오지 않는 사진들이 꽤 있었다. 다른 캠퍼님이 공유해주신 face detection을 사용해 더 정확하게 얼굴을 검출할 수 있도록 구현해봐도 좋았을 것 같다. 

4. Trial 3 – Records

A. 실험 결과 및 인수 기록
실험을 기록할 수 있도록 폴라 코드를 참고하여 실험이 끝나면 자동으로 Github readme와 wandb에 저장되도록 설정했다. 그래서 추후 그 모델을 다시 사용해보고 싶을 때 참고하여 쉽게 재현할 수 있었다.

B. 실험과정 및 새로 배운 내용 기록
시도했던 것들을 모두 기록하여 다음에도 참고할 수 있었으면 했기에 Notion 페이지를 생성하여 수행한 것, 배운 것, 느낀 점 등을 기록하였다. 프로젝트 진행 중에도 뭘 해봤는지, 그에 따른 결과는 어땠는지 잘 기억이 안 날 때 유용하게 사용했다. 시간이 지날수록 더 깨닫겠지만 프로젝트 중에도 기록의 중요성을 알았다. 

1. Retrospection
- 서버를 처음 사용해봐서 초반에 환경 구축하는데 시간이 꽤 오래 걸렸다. 초반엔 시간이 좀 걸렸지만 하고 나니까 실험할 땐 편하게 할 수 있었다. Github 역시 데스크탑으로만 사용해봐서 익숙해지는데 연습이 필요했지만 사용하면서 굉장히 편했기에 역시 도구를 적절히 활용할 줄 알아야 한다는 것을 느꼈다.
- 베이스라인코드를 처음 받았을 땐 어떻게 사용해야할 지 잘 모르겠다는 생각이 들었다. 우선 하나씩 뜯어보기보다는 내 환경에서 돌아갈 수 있도록 수정한 후 여러 세부적인 것들을 고쳐 나가는 것이 시간 대비 효율적으로 코드를 활용할 수 있을 것이라고 생각했다. 그래서 베이스라인을 기준으로 하나씩 뜯어고치다 보니 자연스레 객체지향코드에 대한 이해도도 올라가고 활용 역시 할 수 있게 되어 뿌듯했다. 우선 대충이라도 훑어보고 그 후 자세하게 뜯어보는 것도 괜찮은 방법이라는 생각이 들었다.
- 대회 종료 날 제출 전 마지막으로 수행한 실험에서 augmentation으로 추가한 이미지의 라벨링이 잘못 설정되어 있었다는 걸 깨닫았다. 실수도 실력이다. 다음부터는 실수하지 않게 꼼꼼하게 체크하자는 결심을 했다.
- 나이 라벨을 잘 맞추는 모델과 마스크와 성별을 잘 맞추는 모델을 앙상블 하니 test set에서의 점수가 가장 잘 나왔다. 때때로 팀프로젝트에선 내 것만 고집하기 보다는 상대방의 좋은 것을 가지고 더 나은 방향으로 갈 수 있도록 버리는 용기도 필요하다는 것을 느꼈다.
- 모델 타입이 그리 중요하다고 생각하지는 않아 많이는 변경해보지 않았는데 transformer, efficientnet 등 다양한 모델을 적용해보지 않아서 조금 아쉬웠다. 
