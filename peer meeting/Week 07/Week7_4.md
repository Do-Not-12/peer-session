# Week 7 - Day4

## Today peersession

### 대회 마지막날 한 것들

- 1번 모델 : ResNet18 : 얼굴 400 X 200으로 잘라서 학습한 모델은 고연령을 못 맞추는 경향 발생
- 2번 모델 : ShuffleNet : 이를 보완하고자 원본 데이터에서 59세 밑으로를 60세로 구분해서 모델을 추가 학습
- 3번 모델 : ResNet18 : 2번 케이스에 모델만 변경
- 1번 모델, 2번 모델 결과 앙상블해서 결과를 냈더니 0.7197 -> 0.7571로 점수 대폭 향상함
- 분석해보면 1번 모델은 연령을 제외하고 성별과 마스크분류는 잘 되고 있음
- 2번은 연령대 증강으로 연령대를 잘 맞추는 경향이 발생했음
- 모델만 변경한 3번 모델 진행하니까 0.7571 -> 0.7603 
- Public : 46등 -> 10등 (36등 향상 / 추천트랙 3등) (기적이 일어났다!!!!)
- Private : 최종 12등 (10등 -> 12등) (추천트랙 4등)

### 멘토링

- 배치사이즈랑 learning rate를 동시에 변경함
- sharp한 그래프가 형성되면 dynamic하게 변하는 경우 learning rate가 엄한 곳을 건드리는 경우도 있음
- 초반 수렴속도가 빠르길 바라므로 learning rate를 크게 잡고 decay를 진행
- StepLR을 우선하고 다른 것들을 다양하게 적용해봄
- ML은 decision tree가 결국 best
- DL은 많은 case를 만들고 앙상블하는게 답 (data-driven은 tree적 속성으로 처리하는게 좋을 수 있음)
- loss를 여러개 쓰는 이유
  - loss를 기준으로 loss줄이는 방향으로 fitting한다 = Loss를 기준으로 minimize하므로 기준이 1개
  - 여기서 loss를 여러개를 쓰면 맞추는 기준이 여러 개면 다른 기준에도 맞춰야 하므로 앙상블 효과가 존재할 수 있다고도 함
  - loss를 선형결합하기도 하고 번갈아가면서 적용하는 경우도 있음
- wrap up report는 결과를 보고 역으로 쓰는 것도 좋음
  - 실제는 결과 -> 실험설계지만 쓸때는 실험설계 -> 결과 느낌으로
  - 생각을 많이 하게되면 생각의 과정이 복잡하게 되어 있을 수 있음
    - 이걸 linear하게 잘 엮어주는 게 좋을듯
  - 구체적인 독자를 하나 설정해서 작성하는게 글의 느낌이 너무 벗어나지 않을 수 있음
- 만약 두개의 metric에서 애매한 성능 차를 보낸다면 두 metric이 전반적으로 높은 모델을 선택하는 것이 좋음

