# Week4 - Day3

## Morning Session
- 7강: 도리토스
- 8강: 피터
  - Official tutorial: 폴라
  - Illustrated transformer: 써리

## Today Peersession
#### 07. Recurrent Neural Network Review (도리토스)
  - LSTM
#### 08. Transformer Review (피터)
  - Transformer, Attention에 대해서 설명합니다. 

#### 08. Transformer - Official Tutorials (폴라)
  - 코드를 읽어보는 것이 더 쉽다!

#### 08. Transformer - Illustrated transformer (써리)
  - Q) transformer의 multi-head attention에서 엄청 큰걸 합쳐서 N등분 한다고 했는데, 그걸 N등분 하면 데이터를 훼손하는건지 문제가 없는건지? concatenate
  - Q) Query를 비교할 때 자기 자신이랑 왜 굳이 비교하는지?
  - Q) cee(cross entropy error) 함수가 -log(sigmoid())를 선택했는지 모르겠음.

## 내일 피어세션때는?
  - 폴라의 AlexNet 듣기 ??

## 심화 포스팅 주제
  - 피터 ) 튜토리얼
  - 폴라 ) AlexNet
  - 도리토스 ) 
  - 써리 ) c-GAN